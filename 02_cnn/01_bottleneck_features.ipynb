{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bottleneck_features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/arpitsharma9/01_machine_learning/blob/master/02_cnn/01_bottleneck_features.ipynb)"
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "f0U70qomFlTh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Artificial Intelligence Nanodegree\n",
        "\n",
        "## Convolutional Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "In your upcoming project, you will download pre-computed bottleneck features.  In this notebook, we'll show you how to calculate VGG-16 bottleneck features on a toy dataset.  Note that unless you have a powerful GPU, computing the bottleneck features takes a significant amount of time.\n",
        "\n",
        "### 1. Load and Preprocess Sample Images\n",
        "\n",
        "Before supplying an image to a pre-trained network in Keras, there are some required preprocessing steps.  You will learn more about this in the project; for now, we have implemented this functionality for you in the first code cell of the notebook.  We have imported a very small dataset of 8 images and stored the  preprocessed image input as `img_input`.  Note that the dimensionality of this array is `(8, 224, 224, 3)`.  In this case, each of the 8 images is a 3D tensor, with shape `(224, 224, 3)`."
      ]
    },
    {
      "metadata": {
        "id": "0S566mmMFnTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "f3fcdc4f-31c2-4340-ef14-41f877ae10e1"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J0VGHBk0Nqlr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "ecaa34c2-e67b-4337-e6ae-cd58098c7be9"
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Colab\n",
            "'Colab Notebooks'\n",
            "'resource%20and%20timesheet%20templates (1).xlsx'\n",
            "'resource%20and%20timesheet%20templates (1).xlsx.gdoc'\n",
            " resource%20and%20timesheet%20templates.xlsx\n",
            " resource%20and%20timesheet%20templates.xlsx.gdoc\n",
            " retailorganizationalchart.pptx\n",
            " retailorganizationalchart.pptx.gslides\n",
            " sampleexcelresourcemanagement.xlsx\n",
            " sampleexcelresourcemanagement.xlsx.gdoc\n",
            " write-data-to-text-file.xls\n",
            " write-data-to-text-file.xls.gsheet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HruYCm3VQHVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "744fdade-3ba8-4638-e5ae-e2c04d12a1f3"
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Colab/01-dataset/figures/vgg16.png\"\n",
        "!ls \"/content/drive/My Drive/Colab/01-dataset/figures/vgg16_transfer.png\"\n",
        " "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/Colab/01-dataset/figures/vgg16.png'\n",
            "'/content/drive/My Drive/Colab/01-dataset/figures/vgg16_transfer.png'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t4NRFE_gF1ar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_path=\"drive/My Drive/Colab/01-dataset/images/*.jpg\"\n",
        "#img_path=\"drive/My Drive/Colab/01-dataset/images/sopa.jpg\"\n",
        "#print(img_path)\n",
        "\n",
        "#img = image.load_img(img_path, target_size=(224, 224))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ciLrLh-DFlTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "110d2125-d7f6-44d9-c1c0-636c5d05594c"
      },
      "cell_type": "code",
      "source": [
        "#from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "#Python Imaging Library (abbreviated as PIL) (in newer versions known as Pillow) is a free library for the Python programming language\n",
        "#that adds support for opening, manipulating, and saving many different image file formats. It is available for Windows, Mac OS X and Linux.\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order.\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "#img_paths = glob.glob(\"images/*.jpg\")\n",
        "## a object containing list of images path will be created.\n",
        "img_paths = glob.glob(img_path)\n",
        "print(\"path of images\",img_paths)\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
        "    print(\"list of tensorts\", len(list_of_tensors))\n",
        "    #Stack arrays in sequence vertically (row wise).\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n",
        "# calculate the image input. you will learn more about how this works the project!\n",
        "img_input = preprocess_input(paths_to_tensor(img_paths))\n",
        "\n",
        "print(img_input.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "path of images ['drive/My Drive/Colab/01-dataset/images/sopa.jpg', 'drive/My Drive/Colab/01-dataset/images/Curly-coated_retriever_03896.jpg', 'drive/My Drive/Colab/01-dataset/images/Labrador_retriever_06449.jpg', 'drive/My Drive/Colab/01-dataset/images/Brittany_02625.jpg', 'drive/My Drive/Colab/01-dataset/images/American_water_spaniel_00648.jpg', 'drive/My Drive/Colab/01-dataset/images/Labrador_retriever_06455.jpg', 'drive/My Drive/Colab/01-dataset/images/Welsh_springer_spaniel_08203.jpg', 'drive/My Drive/Colab/01-dataset/images/Labrador_retriever_06457.jpg']\n",
            "list of tensorts 8\n",
            "(8, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "bcWvjYseFlT0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Recap How to Import VGG-16\n",
        "\n",
        "Recall how we import the VGG-16 network (including the final classification layer) that has been pre-trained on ImageNet.\n",
        "\n",
        "![VGG-16 model](\"/content/drive/My Drive/Colab/01-dataset/figures/vgg16.png\")"
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "l6s8eOi-FlT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "12ccad0d-4a98-420e-b1db-e0078ec64198"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16()\n",
        "model.summary()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 15s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zdTXBXpOFlUA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this network, `model.predict` returns a 1000-dimensional probability vector containing the predicted probability that an image returns each of the 1000 ImageNet categories.  The dimensionality of the obtained output from passing `img_input` through the model is `(8, 1000)`.  The first value of `8` merely denotes that 8 images were passed through the network."
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "i0UL17snFlUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c16a7d02-8edb-4f72-e201-03859c3f36de"
      },
      "cell_type": "code",
      "source": [
        "model.predict(img_input).shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "wfEgKTFTFlUG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Import the VGG-16 Model, with the Final Fully-Connected Layers Removed\n",
        "\n",
        "When performing transfer learning, we need to remove the final layers of the network, as they are too specific to the ImageNet database.  This is accomplished in the code cell below.\n",
        "\n",
        "![VGG-16 model for transfer learning](figures/vgg16_transfer.png)"
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "g2prYbXmFlUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "ac47b7ee-441e-4758-ffbf-66a17803282f"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16(include_top=False)\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eVRYNizCFlUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Extract Output of Final Max Pooling Layer\n",
        "\n",
        "Now, the network stored in `model` is a truncated version of the VGG-16 network, where the final three fully-connected layers have been removed.  In this case, `model.predict` returns a 3D array (with dimensions $7\\times 7\\times 512$) corresponding to the final max pooling layer of VGG-16.  The dimensionality of the obtained output from passing `img_input` through the model is `(8, 7, 7, 512)`.  The first value of `8` merely denotes that 8 images were passed through the network.  "
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yGB4cIzsFlUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60ae6ed0-d0e0-449d-9d5d-04755602492e"
      },
      "cell_type": "code",
      "source": [
        "print(model.predict(img_input).shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 7, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "72VfxZ_yFlUT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is exactly how we calculate the bottleneck features for your project!"
      ]
    }
  ]
}